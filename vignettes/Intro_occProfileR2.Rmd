---
title: "Classifying Occurrence Data with *occTest*"
author: "Pep Serra-Diaz, Cory Merow"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Profiling Occurrence Data with occTest}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

# What does occTest do?

*occTest* implements a workflow to integrate, assess and control data quality of species occurrences, and is especially designed species distribution analysis and modelling. The quality control workflow follows a hierarchical procedure (Figure 1; see Serra-Diaz et al. 2018 and Figure 1) and profiles the occurrences according to several checks on the coordinates and environmental layers. 

Profiling should not be understood as data cleaning, but rather as the application of several tests that enable the user to characterize an occurrence record. Such profiling should enable the user to make choose the best analysis with the data at hand and understand the limits of the data. This is differs from the more classical approach of data selection, cleaning or scrubbing, but it is obviously a critical step prior to cleaning data for a given analysis. 

The packages is based on a combination of new created functions by J.M. Serra-Diaz, C.Merow and B.Maitner, and a wrapper of functions from packages biogeo (Patterson et al. ) and CoordinateCleaner(Zizka et al. ).

![](occTest.png) 


## Workflow overview and data needed

The main function, that implements the workflow is called *occurrenceClassify*. The workflow is divided in several steps detailed below, but it consist of two main procedures: the filtering procedure and the analysis procedure (Fig.1). The filtering procedure flags occurrences that are not useable for SDMs and a strong correction of the coordinates is needed (see biogeo package for potential solutions). The analysis procedure undertakes several analysis (e.g. geographical outliers, environmental outliers) using multiple tests in each analysis in order to assess (e.g. 'profile') potential errors.  


The workflow NEEDS a MINIMUM of THREE parameters: 

1. Species name (sp.name; character)

2. Species occurrence dataset (sp.table; data.frame) 
The species occurrence data.frame contains the presence records in latitude-longitude WGS84 geographic coordinate system, with column name 'x' for longitude and column name 'y' for latitude (NOTE: these column names can be flexible and user defined, see below, but 'x' and 'y' are the defaults) 

3. Environmental raster (r.env; rasterStack), with quantitiative continuous variables such as a climate.
The environment raster is a rasterStack object that contains the climate variables intended for use in an SDM or another analysis relating species occurrence and climate. 

```{r}
#load data
library(spocc)
df <- occ(query = 'Martes martes')
occ.data <-occ2df(df)

#we change the names here but we could just change it in the tableSettings
names (occ.data)[2] <- 'decimalLongitude'
names (occ.data)[3] <- 'decimalLatitude'

#load needed environmental data
library (raster)
environmentRaster = raster::getData(name='worldclim',var='bio', res=10)

#classify occurrences
library(occTest)
outMartesMartes = occTest::occTest(sp.name='Martes martes', sp.table = occ.data,r.env = environmentRaster)
```

## *occurrenceProfile* output

The outputs of occurrenceProfile is a list with two elements:

1. occ_full_profile : a dataframe with coordinates , and the profile labeling system, as well as the general results for each kind of analysis (geoOutliers, envOutliers) and each one of the tests perfomed on the data.


```{r}
#check the output
class(outMartesMartes)
names (outMartesMartes)

str(outMartesMartes$occ_full_profile)
str(outMartesMartes$occ_short_profile)

#

```
2. occ_short_profile :a dataframe with coordinates , and the profile labeling system, as well as the general results for each kind of analysis (geoOutliers, envOutliers)

```{r}
#check the SHORT output
str(outMartesMartes$occ_short_profile)
#

```
### Occurrence labeling scheme

To ease the rapid interpretation of many analyses we developed a labeling system to quickly describe data in terms of quality for SDMs. Each label is composed of two elements: a grade (ranging from A to H, capital letter) and a qualifier(s) (letter(s) that further describes the occurrence record). 

Grades are meant to identify potential quality issues that compromise or largely affect SDMs, while qualifiers are meant to indicate that the selection of a particular occurrence is tied to a specific use. For instance, grades will help you differentiate between duplicated records, or missing coordinates, and qualifiers will inform you whether the record has a timestamp or whether it is in an invasive or native region 
Example:  
A record is characterized by the profiling label *A/n-t-p*  
This means:  
*Grade*     : A  no apparent errors found  
*Qualifiers*: n (occurrence in the native range)  
              t (timestamp available in the occurrence record)  
              p (coordinate precision ok)  

Grade labels currently implemented:    


| Label         | Label name                                                | Other info  |
| ---- |:-----------------------------------------:| -----------------:|
| H             | Missing coordinates                                       | |
| G             | Duplicated records                                        |   Either raster cell dups or exact coordinate dups |
| F             | Unknown range or wrongly reported                         | |
| E             | Wrong (or unlikely) environment      |Missing environmental info, or in botanic garden or sea |
| D             | Geographic and Environmental issues       |Flags for both geographical and environmental space have been raised in the analysis|
| C             | Environmental issues     |  Flags environmental space have been raised in the analysis|
| B             | Geographical issues      |    Flags geographical space have been raised in the analysis|
| A             | No issues detected      |   No issues detected|


Qualifiers  currently implemented

| Qualifier label         | Qualifier description                                             
| ------------- |:---------------------------------------------------------:|
| t             | timestamp present in the record                             | 
| p             | good precision with respect tot the environmental raster provided |   
| i             | record in the invasive range                      | 
| n             | record in the native range      |Missing environmental info, or in botanic garden or sea |
| e             | record with elevation difference between elevation raster and recorded elevation less than a given threhsold   


### Inspect the results 

We acknowledge that users may have differnt thoughts and visions on how to classify occurrences, so we also show in the output the different tests performed and whether they passed the test or not (. Users will thus be able to classify the occurrences the way they want to. 

In *occ_full_profile* different fields show the results of each analysis. The names of the fields show the following rationalle:

[AnalysisType]_[SpecificTest]_test: binary. Shows whether the occurrence passes or not the test, being 1 a flag for a wrong record. 
[AnalysisType]_[SpecificTest]_comment: character. Shows some comments related to the specific test.
[AnalysisType]_comment: numeric. Averages the results of different tests performed


Examples: 

*institutionLocality_fromBotanicLocalityName_test* is a test (1/0) that tries to identify records located in biodiversity institutions, with the specific method of interpreting locality names using a set of keywords.
*institutionLocality_score* summarizes all the test to identify records located in biodiversity institutions an outputs a value from 0 to 1. A value of 0.5 would indicate that half of the methods used indicate that is an insitution locality. 


### Checking occurrences against checklists


Set interactiveMode=T If you would like to interact with the workflow and take some decisions as you go. Right now, it asks whether you want the workflow to query several databases to find out checklists where your target species has been cited as native or invasive.


## Customizing your analysis

Many specifications may be set to profile occurrences, although not all will be useful in all cases. We guide you here to set specific parameters to your analysis.

### tableSettings: when you have more than xy in your table

Some occurrence data has more than x and y coordinates. If that is the case you can provide important information. The parameter *tableSettings* consists of a list with the following elements that should be identified. Note that even if you want to change only one value of the default you need to provide a full list, with each named elements.

| Named element in list    | Description     | Value  |
| ----------   |:------------------------------:| -------:|
taxonobservation.id | Name of the colum in the species table for the observation ID | character
x.field             | Name of the colum in the species table for the longitude | character
y.field             | Name of the colum in the species table for the latitude | character
t.field            | Name of the colum in the species table for the observation date | character
l.field             | Name of the colum in the species table for the locality name | character
c.field            | Name of the colum in the species table for the REPORTED COUNTRY  | character
e.field             | Name of the colum in the species table for the REPORTED ELEVATION (in meters) | character
a.field              | Name of the colum in the species table for the accuracy (in meters) of the coordinates  | character
ds.field          | Name of the colum in the species table for the source of the data  | character


### analysisSettings: when you want to select or change the analysis
Do you want to set up differnt implementations of the analysis? Set up your own parameters. The parameter *analysisSettings* consists of a list with the following elements that should be identified. Note that even if you want to change only one value of the default you need to provide the full list, with each named elements.



| Named element in list    | Description     | Value  |
| ----------   |:------------------------------:| -------:|
\$geoSettings\$coordinate.decimal.precision | decimal precision of the coordintes | numeric
\$geoSettings\$points.proj4string | Projection to use | Proj4 character. CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
\$rangeAnalysis\$countryfield.shapefile | spatialPolygonsDataFrame with the countries and their associated names or ISO3 codes in the dataframe | spatialPolygonsDataFrame. Defaults to rnaturalearth::ne_countries()
\$rangeAnalysis\$doRangeAnalysis | whether the user wants to do perform the analysis of comparing coordinates countries to reported native or invasive countries | logical. Dafaults to T 
\$rangeAnalysis\$excludeUnknownRanges | keep the analysis for occurrences out of the known native or alien countries? | logical. Defaults to F
\$rangeAnalysis\$doCountryRecordAnalysis | whether the user wants to do perform the analysis of comparing reported countries to reported native or invasive countries | logical. Dafaults to T 
\$rangeAnalysis\$excludeNotmatchCountry keep the analysis for occurrences when the reported country is different than the native or alien countries? | logical. Defaults to F
\$centroidAnalysis\$doCentroidDetection | whether the user wants to do perform the analysis of centroid detection | logical. Dafaults to T 
\$centroidAnalysis\$methodCentroidDetection | methods to use to detect centroids. Implemented are: 'BIEN','speciesGeoCodeR','CoordinateCleaner', 'all' | character. Dafaults to 'all' 
\$humanAnalysis\$doHyperHumanDetection | whether the user wants to do perform the analysis of human influence | logical. Dafaults to T
\$humanAnalysis\$methodHyperHumanDetection | what methods to use to detect high human influence Implemented are: 'hii','urban', 'all' | character. Dafaults to 'all' 
\$humanAnalysis\$th.human.influence | when methods are 'all' or 'hii' what is the threshold value for human influence | numeric. Dafaults to 40  
\$humanAnalysis\$ras.hii | raster of the human influence index | raster. Defaults to SEDAC human infuence index | raster
\$institutionAnalysis\$doInstitutionLocality | whether the user wants to do perform the analysis of records potentialy in biodiversity institutions | logical. Dafaults to T 
\$institutionAnalysis\$methodInstitutionLocality | methods to use to detect records  in biodiversity institutions Implemented are: 'fromBotanicLocalityName','fromCoordinates', 'all' | character. Defaults to 'all'  
\$geooutliersAnalysis\$doGeoOutliers | whether the user wants to do perform the analysis of geographical outliers  | logical. Dafaults to T 
\$geooutliersAnalysis\$methodGeoOutliers | methods to use to geographic outliers. Implemented are: 'alphaHull','distance','median','quantSamplingCorrected','grubbs, 'all' | character. Defaults to 'all'  
\$geooutliersAnalysis\$alpha.parameter | alpha parameter desired for method 'alphaHull' | numeric. Defaults to 2
\$envoutliersAnalysis\$doEnvOutliers | whether the user wants to perform the analysis of environmental outliers | logical. Dafaults to T 
\$envoutliersAnalysis\$methodEnvOutliers | methods to use to environmental outliers. Implemented are: 'bxp','grubbs', 'all' | character. Defaults to 'all'  
\$envoutliersAnalysis\$th.perc.outenv | for method 'bxp' what is the percentage of variables found as an outlier to define it as an outlier | Numeric. Defaults to 0.2
\$accuracyAnalysis\$do.geoEnvAccuracy | whether the user wants to perform the accuracy analysis | logical. Dafaults to T 
\$accuracyAnalysis\$methodGeoEnvAccuracy | methods to use for the accuracy analysis. Implemented are: 'envDeviation','percDiffCell', 'elevDiff','lattice','rasterCell','all'| character. Defaults to 'all'  
\$accuracyAnalysis\$elev.quality.threshold | for elevDiff method, threshold of the difference between reported and inferred elevation | numeric. Defaults to 100

### gradingSettings: when you want to select or change the analysis

The user can decide different ways to implement the grading system through different parameters in the list *gradingSettings*


| Named element in list    | Description     | Value  |
| ----------   |:------------------------------:| -------:|
\$grading.test.type | How to consider the consensus when several methods implemented differ? Options implemented are: 'majority','strict' 'relaxed. For instance, 'strict' will flag a record as a geographic outlier if there is at least a method flagging it. 'majority' when the majority of methods agree and 'relaxed' when more than 70% of the methods agree. | charcter. Defaults to 'majority'   
\$qualifiers | should qualifiers be implemented | Logical. Defaults to T                       
\$qualifier.label.scoping | over which grades should qualifiers be implemented |character. Defaults to c('A','B','C','D','E') (all labels applied by default)

### writeoutSettings: do you want to write the outputs?

The user can specify if outputs are to be written.

| Named element in list    | Description     | Value  |
| ----------   |:------------------------------:| -------:|
\$output.dir | Name of the output directory | character.Defaults to NULL
\$writeAllOutput | should all outptus be written | logical. Defaults to F 
\$write.simple.output | should simple output table be written | logical. Defaults to F 
\$write.simple.output | should full output table be written | logical. Defaults to F 
\$output.base.filename | what is the suffix of the output table filename? | character. Deafaults to 'QAQC'

### an example of how to modify settings

We do not want to do the accuracy analysis in the workflow because we believe our data is accurate enough and/or we do not have enough information

```{r}
#load default settings
mySettings <- defaultSettings()
#change the attribute of interest (in this case setting an analysis off)
mySettings$analysisSettings$accuracyAnalysis$do.geoEnvAccuracy = F
#add your settings to the function
out = occTest(sp.name='Martes martes', sp.table = occ.data,r.env = environmentRaster, 
                         analysisSettings = mySettings$analysisSettings)


```


## The occTest workflow step by step

### Step 0: Initial checks

Before starting the workflow the test checks that input data is correct, and tries to identify country checklists where the species may be considered native and or invasive (depending on your settings).

| Function name    | What it does...      | Output  |
| ----------   |:------------------------------:| -------:|

nativeStatusCtry | checkes whether a species is found in different databases as native or as invasive | list with two elements: [['ntvCtry']], [['invCtry']]. These indicate the ISO3 codes of the countries where the species is considered native and invasive, respectively. 

### Step 1: Filter missing data and geographical errors [FILTER PHASE]

First, the workflow checks whether there are missing data with the *filterMissing* function.

| Function name    | What it does...      | Output  |
| ----------   |:------------------------------:| -------:|
| filterMissing    | Filters records with missing coordinates |  list with two elements 'stay' (dataframe with filtered records); 'continue' (dataframe with elements that passed the test)

Then it checks whether the coordinates are in geographic latlong WGS84 and performs three tests in the CoordinateCleaner package: the zero long zero latitude, and decimal conversion errors. If errors are found, these records are filtered from subsequent analysis, and categorized as H. 

### Step 2: Filter duplicate records [FILTER PHASE]

Records are checked to see if these are duplicated. We differentiate whether records are exact coordinate duplicates, or whether they are they are duplicates in the environment, meaning they fall within the same environmental grid cell.

| Function name    | What it does...                                                | Output  |
| -------------    |:------------------------------------------------:| --------------------:|
| duplicatesexcludeAnalysis    | Filters duplicates AND differentiates between exact duplicates and raster cell duplicates |  list with two elements 'stay' (dataframe with filtered records); 'continue' (dataframe with elements that passed the test)

### Step 3: Sea/Terrestrial potential reassignment [FILTER PHASE]

Check whether species are in an incorrect habitat (e.g. sea for a terrestrial species) and tries to correct it. Correction happens when a neighbor cell in the environmental raster has environmental data (unlike the target cell). If records could be corrected, then it goes back to step 2 to check for duplicates again. Based on the correction methods in packages biogeo.

| Function name    | What it does...                                                | Output  |
| -------------    |:------------------------------------------------:| --------------------:|
| nearestcell3    | Moves sea records to terrestrial coordinates, an original record is kept |  if list => two elements 'moved' (dataframe with moved coordinates); 'not moved' 

### Step 4: Country-related range analysis [OPTIONALLY FILTER PHASE]

In this step we perform the analysis to know whether the species is outside of the countries where it is considered native or invasive, or to see whether it is out of the recorded country. If no information on native or invasive range, then all records are considered good and the analysis continues to step 5. 

This analysis may be filter records for subsequent steps or not(the default). If users want to set this test as a test, and thus highlight records not found in known ranges, then they can set *excludeUnknownRanges*=T and *excludeNotmatchCountry*=T in *occurrenceProfile* function.

| Function name    | What it does...                                                | Output  |
| -------------    |:---------------------------------------------------------:| -----------:|
| countryStatusRangeAnalysis    | Checks three things: is the species in the native range country ? is the species in the invasive range country? is the species recorded in a country different than the country extracted from coordinates? |  by default (unless excludeUnknownRanges= T OR excludeNotmatchCountry= T in the workflow), added columns for each of this tests with values 1/0/NA.

### Step 5: Geoenvironmental analysis

Perform several tests to flag environmental and geographical issues of the records. All records that have not been filtered in Steps 1-4 are passed through a set of different functions specified below. 

| Function name    | description of the tests                                               
| -------------    |:---------------------------------------------------:|
| centroidDetection    | is record  found in a centroid of a political entity? | 
| HumanDetection  | is record found in a highly human environment (agriculuture, urban areas)? | 
| institutionLocality  | is record found near an institution (GBIF, botanic garden)? |
| geoOutliers    | is record a geographical outlier?  |
| envOutliers    | is record an environmental outlier? |
| geoEnvAccuracy    | tests whether the coordinates are precise and whether they may compromise the accuracy of environmnetal data? |  

Each of these functions aims at identifying different potential errors of occurrence records. However, different methods have been implemented to identify them. In occTest we implement an ensemble testing. That is, the default is to test different methods for each of the functions and output a score that average the results. For instance, detecting geographical outliers can be performed using different methods: by using distances between points, by using coordinate distributions, by using alpha hull geometries. occurrenceProfile tests all of them and outputs 1 or 0 for each method, and a total score ranging from 0 to 1 for geographical outlier detection. The user may, however, specify which tests to perform although our default and recommendation is to use them all (method='all' in all functions above). 

| Function name    | methods                                               
| -------------    |:---------------------------------------------------:|
| centroidDetection    |'BIEN'  |
| centroidDetection    |'speciesGeoCodeR' |
| centroidDetection    |'CoordinateCleaner', implemented from the DB of centroids from the pckg with the same names  |
| HumanDetection    |'hii' using the human influence index from NSDIC  | 
| HumanDetection    |'urban' using human areas from the naturalearth website | 
| institutionLocality    |'fromBotanicLocalityName' using text recognition pattern to identify different names associated with botanical records in the field locality  | 
| institutionLocality    |'fromCoordinates' matching coordinates of the record with known institution coordinates  | 
| geoOutliers    | 'alphahulls' using alpha hull geometry (alpha parameter=2) to destinguish point out of the alpha hull |  
| geoOutliers    | 'distance' outliers ar flagged if the minimum distance to the next record of the species is >   .distance.parameter (default 1000, but can be changed). Check ?CoordinateCleaner::cc_outl for further info |  
| geoOutliers    | 'median' outliers are identified *if the mean distance to all other records of the same species is larger than the median of the mean distance of all points plus/minus the mad of the mean distances of all records*. Check ?CoordinateCleaner::cc_outl for further info|  
| geoOutliers    | 'quantSamplingCorrected' use mean distances to identify outliers, but based on country specific sampling intensity. Check ?CoordinateCleaner::cc_outl for further info |  
| geoOutliers    | 'grubbs' uses three tests dicussed by Grubbs (1950) to identify outliers. Check ??outliers::grubbs.test for further information |  
| envOutliers    | 'bxp' uses boxplot statistics to idientify an outlier. Check ?biogeo::outlier for further information  |  
| envOutliers    | 'grubbs' uses three tests dicussed by Grubbs (1950) to identify outliers. Check ??outliers::grubbs.test for further information |  
| geoEnvAccuracy    | 'lattice' checking potential errors when data comes from catalogue data. See ?CoordinateCleaner::cd_round for further information |  
| geoEnvAccuracy    | 'percDiffCell' given a field(s) of coordinate accuracy, identify if the occurrence could be >50% in a different cellfrom the original coordinates (reported coordinates) |  
| geoEnvAccuracy    | 'envDeviation' given a field(s) of coordinate accuracy, identify if the occurrence deviates environmentally from the original coordinates (reported coordinates) |  
| geoEnvAccuracy    | 'elevation': given an elevation field, identify occurrences for which the reported elevation and the elevetion in the cell is more than 100m |

### Step 6: Perform the quality grading system 

In this step we use the different checks performed (filtering occurrences in steps 1-4 and analysis in step 5)to implement a grading system that allows each record to be labeled (e.g profiled, see section on label scheme). 

| occurrenceProfile Parameters    |  it does...                                                | options  |
| -------------    |:---------------------------------------------------:| ----------------:|
| grading.test.type    | When multiple tests are implemented for a given type of check (e.g geographical outliers), you need to decide how much you are willing to accept.  | charachter. 'majority' flags errors where >50% of the methods in step 5 raised a flag. Other options are 'strict' (>0%) and 'relaxed' (>60%)|
| qualifiers    | Logic. TRUE or FALSE   | it implements tags to characterize the label, to quickly identify whether you have timestamp in the record, or if it is in the native or invasive range|
| qualifier.label.scoping    | character. Defalut is all labels implemented c('A','B','C','D','E')   | it implements tags to characterize the label, but you can choose in which labels you want to implement those tags. For instance, you may be interested to know these details for label A or B, then you should change that parameter|

### Step 7: Write outputs 

In this last step, we write the desired outputs.

| occurrenceProfile Parameters    | options                                                | What it does  |
| -------------    |:---------------------------------------------------:| ----------------:|
| write    |  Logic. Default to F. Overwrites write.simple.output and write.full.output   | It writes two csv files with the profiled records |
| write.simple.output    |Logic. Default to F  | It writes the csv files with the profiled records, with a limited number of information |
| write.full.output    |Logic. Default to F  | It writes the csv files with the profiled records, with a all analysis outputs|
| output.base.filename    |Character. Default to 'QAQC'  | suffix used to write the output files|


# Example 1: The hands-off analysis (default)


```{r}
#load packages
library(occTest)
library(spocc)


df <- occ(query = 'Pseudotsuga menziesii')
occ.data <-occ2df(df)

#we change the names here but we could just change it in the tableSettings
names (occ.data)[2] <- 'x'
names (occ.data)[3] <- 'y'

#load needed environmental data
library (raster)
rrr = raster::getData(name='worldclim',var='bio', res=10)

#classify occurrences but we will ask to resolve native and invasive countries (this obviously takes longer)
library(occTest)
outDougFir = occurrenceClassify(sp.name='Pseudotsuga menziesii', 
                                sp.table = occ.data,
                                r.env = rrr,
                                resolveAlienCtry = T, 
                                resolveNativeCtry = T,
                                verbose = T)


#check SHORT outputs
str(outDougFir$occ_short_profile)


```

```{r}
#see the classification
table (outDougFir$occ_full_profile$quality.grade)
```


# Example 2: Making the function turn with more detailed data (and more options)


```{r,fig.width=6,fig.height=4}
#load packages
library(occTest)
library(ggplot2)
library(raster)
library(knitr)
library(rgdal)

#load data
occ.species.nogeoscrub.f = system.file('ext/SampleData/Sp3Occurrence_v4.csv'
                                     ,package='occTest')
occ.species.nogeoscrub <-  read.table (file = occ.species.nogeoscrub.f,header = T,sep = ',',as.is = T)


#load the reaster of the environmental variables
ras.env.f = system.file('ext/AllEnv.tif',package='occTest')
ras.env = raster::stack(ras.env.f)

#load a high resolution raster of elevations
ras.dem.f = system.file('ext/DEM.tif',package='occTest')
ras.dem = raster(ras.dem.f)


######## CHECK THE INPUT DATA TABLE
str (occ.species.nogeoscrub)

```
The sample species is a Mediterranean that is present in France, Spain and Andorra. But the information of the species is however variable. Some records have the date collected, other records have data on the elevation, others have information on the locality, etc... 

The table data shows:
- Longitude and latitude are named as MAPX and MAPY (MAPX, MAPY)
- There is a recorded name of a country in the table (COUNTRYRECORD)
- Locality name field (LOCALITYNAME)
- Uncertainty field value (UNCERTEINTY_X_M, UNCERTAINTY_Y_M)
- Date field (DATE)

We will incorporate this information into the workflow. To do so we need to modify the defaultSettings relatedo to table

```{r}
mySettings <- occTest::defaultSettings()
mySettings$tableSettings$x.field <- 'MAPX'
mySettings$tableSettings$y.field <- 'MAPY'
mySettings$tableSettings$t.field <- 'DATE'
mySettings$tableSettings$l.field <- 'LOCALITYNAME'
mySettings$tableSettings$c.field <- 'COUNTRYRECORD'
mySettings$tableSettings$e.field <- 'ELEVATION'
mySettings$tableSettings$a.field <- c('UNCERTAINTY_X_M','UNCERTAINTY_Y_M')

```

We have a more detailed raster of human influence than that of the report. In our of map high human influence is considered when a record is in a cell above 50. Let's modify our settings 

```{r}
#load your own human influence map
ras.humaninfluence.f = system.file('ext/HII.tif',package='occTest')
ras.humaninfluence = raster(ras.humaninfluence.f)

#add it to the settings
mySettings$analysisSettings$humanAnalysis$th.human.influence <-50
mySettings$analysisSettings$humanAnalysis$methodHyperHumanDetection <-ras.humaninfluence

#plot it
#plot(ras.humaninfluence)
```

We also have a more detailed data on country borders 
```{r}
#load detailed country borders and shorelines
countries.pol.f = system.file('ext/CountryLevel',package='occTest')
countries.pol = readOGR(dsn = countries.pol.f,layer='Countries_SPDF_MED')
names (countries.pol)

#add it to the settings
mySettings$analysisSettings$rangeAnalysis$countries.shapefile <-countries.pol 
mySettings$analysisSettings$rangeAnalysis$countryfield.shapefile <- 'ISO' 

```

We also know that the species is native to Spain ('ESP') and considered invasive in France ('FRA') so we will also specify it. Because we have such detailed information, anything that is not in these two countries will not be graded as high quality.


```{r}
out <- occurrenceClassify(sp.name = 'My species',
                          sp.table = occ.species.nogeoscrub,
                          r.env =ras.env,
                          tableSettings = mySettings$tableSettings, 
                          analysisSettings =mySettings$analysisSettings,
                          r.dem =   ras.dem,
                          ntv.ctry = 'ESP',
                          inv.ctry = 'FRA',
                          verbose = T)

table (out$occ_short_profile$quality.label)

```
Now let's plot the results in a map

```{r}
# 
# full.qaqc <-out$occ_full_profile
# proposed.color.grading <- data.frame (row.names =
#                                         c('A','B','C','D','E','F','G','H'),
#                                       color.qgrade=c('#4575b4','#74add1',
#                                                      '#abd9e9','#e0f3f8',
#                                                      '#fee090','#fdae61',
#                                                      '#f46d43','#d73027'))
# color.to.plot<-as.character(sapply(full.qaqc$quality.grade,
#                                    function (x){
#                                      proposed.color.grading[x,'color.qgrade'] }))
# plot(ras.dem)
# points(x=full.qaqc$MAPX,y=full.qaqc$MAPY,col='black',pch=22,bg=color.to.plot)
```
